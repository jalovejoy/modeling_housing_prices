{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Importing Libraries & Loading Data](#Importing)\n",
    "2. [Cleaning & Preparing Data](#Clean&Prep)\n",
    "    1. [Renaming columns](#Renaming)\n",
    "    2. [Dropping bad data](#DropBadData)\n",
    "    3. [Resetting values & types](#ResetValues)\n",
    "3. [Populating Null Values](#PopulatingNulls)\n",
    "4. [Adding Metrics & Features](#AddingMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TO DO IN FUTURE ####\n",
    "## 1) Improve BsmtQual fill model for Nulls in test data\n",
    "## 2) Add new features (lot area??) ## Would need to get creative on building new one ##\n",
    "## 3) Remove low impact features as I add higher impact one\n",
    "## 4) Better clean the data...\n",
    "## 5) Figure out a way to be smarter to weight inputs into meta-features (ie. TotalArea)\n",
    "#### TO DO IN FUTURE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importing Libraries & Loading Data<a name=\"Importing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Cleaning & Preparing Data<a name=\"Clean&Prep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns<a name=\"Renaming\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to replace spaces in the column titles\n",
    "def remove_space(df):\n",
    "    col_no_space = []\n",
    "    for col in list(df.columns):\n",
    "        col_no_space.append(col.replace(' ',''))\n",
    "    return col_no_space\n",
    "\n",
    "## Removing spaces from column titles in both test sets\n",
    "train.columns = remove_space(train)\n",
    "test.columns = remove_space(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping bad data<a name=\"DropBadData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping all columns from train data where more than 40% of the data is missing\n",
    "train.drop(columns=['Alley','PoolQC','Fence','MiscFeature','FireplaceQu'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting values & types<a name=\"ResetValues\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting CentralAir to binary\n",
    "train['CentralAir'] = [1 if x =='Y' else 0 for x in train['CentralAir']]\n",
    "test['CentralAir'] = [1 if x =='Y' else 0 for x in test['CentralAir']]\n",
    "\n",
    "## Set MSSubClass to a series of strings (categorical)\n",
    "train['MSSubClass'] = train['MSSubClass'].astype(str)\n",
    "test['MSSubClass'] = test['MSSubClass'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sets dictionary to recategorize quality as numeric value (higher = better)\n",
    "recat_dict = {\n",
    "    'Ex' : 5,\n",
    "    'Gd' : 4,\n",
    "    'TA' : 3,\n",
    "    'Fa' : 2,\n",
    "    'Po' : 1,\n",
    "    'Na' : 0,\n",
    "    'GLQ' : 6,\n",
    "    'ALQ' : 5,\n",
    "    'BLQ' : 4,\n",
    "    'Rec' : 3,\n",
    "    'LwQ' : 2,\n",
    "    'Unf' : 1,\n",
    "    'NA' : 0,\n",
    "    'Av' : 3,\n",
    "    'Mn' : 2,\n",
    "    'No' : 1,\n",
    "    'Fin' : 3,\n",
    "    'RFn' : 2\n",
    "    \n",
    "}\n",
    "\n",
    "## Replaces quality indices with numeric values\n",
    "train.replace(to_replace=recat_dict, inplace=True)\n",
    "test.replace(to_replace=recat_dict, inplace=True)\n",
    "\n",
    "## Changes these types to a float\n",
    "train[['ExterQual','BsmtQual','KitchenQual','GarageQual','BsmtFinType1','BsmtFinType2',\n",
    "      'HeatingQC','GarageCond','BsmtExposure']] = \\\n",
    "train[['ExterQual','BsmtQual','KitchenQual','GarageQual','BsmtFinType1','BsmtFinType2',\n",
    "      'HeatingQC','GarageCond','BsmtExposure']].astype(float)\n",
    "\n",
    "test[['ExterQual','BsmtQual','KitchenQual','GarageQual','BsmtFinType1','BsmtFinType2',\n",
    "      'HeatingQC','GarageCond','BsmtExposure']] = \\\n",
    "test[['ExterQual','BsmtQual','KitchenQual','GarageQual','BsmtFinType1','BsmtFinType2',\n",
    "      'HeatingQC','GarageCond','BsmtExposure']].astype(float)\n",
    "\n",
    "### NOTE: I tested a few of these beforehand to make sure the numeric scales had higher correlations than\n",
    "### any of the dummy variables. I find that using numbers make sense and the correlations seem\n",
    "### stronger than creating dummy variables for Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Populating null values<a name=\"PopulatingNulls\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data: Basement Quality\n",
    "In the test data, basement quality (BsmtQual) had a number of Null or NaN values. Since the feature is paramount to the final model, a sub-model (EDA below) was used to fill in these Nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up X and y for filling in Basement Quality on test data\n",
    "bsmt_qual_filter = ['BsmtQual','YearBuilt','OverallQual','ExterQual','KitchenQual']\n",
    "bq_df = test[bsmt_qual_filter].dropna()\n",
    "y_test_bq = bq_df['BsmtQual']\n",
    "X_test_bq = bq_df[bsmt_qual_filter].drop(columns=['BsmtQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "## Instantiating ridge model and standard scaler\n",
    "ridge = RidgeCV(cv=5)\n",
    "SS = StandardScaler()\n",
    "\n",
    "## Scaling the X data\n",
    "X_test_bq_s = SS.fit_transform(X_test_bq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model\n",
    "ridge.fit(X_test_bq_s, y_test_bq)\n",
    "X_test_bq_full = test[bsmt_qual_filter].drop(columns=['BsmtQual'])\n",
    "X_test_bq_full_s = SS.transform(X_test_bq_full)\n",
    "\n",
    "## Predicting Basement Quality\n",
    "test['BsmtQualPreds'] = ridge.predict(X_test_bq_full_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling Test BsmtQual Nulls with predictions\n",
    "test['BsmtQual'].fillna(value=test['BsmtQualPreds'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Adding Metrics & Features<a name=\"AddingMetrics\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining new metric for how old the house is\n",
    "train['HouseAge'] = 2019 - train['YearBuilt']\n",
    "test['HouseAge'] = 2019 - test['YearBuilt']\n",
    "\n",
    "#### This ended up not being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining new metric for the total area of the house based on combination of individual house areas\n",
    "#### NOTE: Weighted according to strength of correlation.\n",
    "#### NOTE: TotalArea is not actually in square feet anymore\n",
    "\n",
    "train['TotalArea'] = (0.628925 * train['TotalBsmtSF']) + (0.697038 * train['GrLivArea'])\\\n",
    "+ (0.650270*train['GarageArea']) - (0.045328*train['LowQualFinSF'])\n",
    "\n",
    "test['TotalArea'] = (0.628925 * test['TotalBsmtSF']) + (0.697038 * test['GrLivArea'])\\\n",
    "+ (0.650270*test['GarageArea']) - (0.045328*test['LowQualFinSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining new metric for total Quality\n",
    "#### NOTE: Weighted according to strength of correlation.\n",
    "\n",
    "train['QualMetric'] = (0.692336*train['KitchenQual']) + (0.678307*train['BsmtQual']) + \\\n",
    "(0.712146*train['ExterQual']) + (0.800207*train['OverallQual'])\n",
    "\n",
    "test['QualMetric'] = (0.692336*test['KitchenQual']) + (0.678307*test['BsmtQual']) + \\\n",
    "(0.712146*test['ExterQual']) + (0.800207*test['OverallQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining new metric for Total Baths\n",
    "#### NOTE: Half baths are multiplied by... wait for it... half\n",
    "#### This intuitively makes sense and seems to drive stronger correlations\n",
    "\n",
    "train['TotalBaths'] = train['BsmtFullBath'] + train['FullBath'] + \\\n",
    "(0.5*train['HalfBath']) + (0.5*train['BsmtHalfBath'])\n",
    "\n",
    "test['TotalBaths'] = test['BsmtFullBath'] + test['FullBath'] + \\\n",
    "(0.5*test['HalfBath']) + (0.5*test['BsmtHalfBath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining new metric for total Porch or Deck Area\n",
    "#### NOTE: Weighting by correlations didn't add value here.\n",
    "\n",
    "train['PorchArea'] = train['ScreenPorch'] + train['3SsnPorch']\\\n",
    "+ train['OpenPorchSF'] + train['EnclosedPorch'] + train['WoodDeckSF']\n",
    "\n",
    "test['PorchArea'] = test['ScreenPorch'] + test['3SsnPorch']\\\n",
    "+ test['OpenPorchSF'] + test['EnclosedPorch'] + test['WoodDeckSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining function to find and return DataFrame with only the dummy variables that\n",
    "## have a correlation > 0.15\n",
    "\n",
    "def find_corr_dummies(df,col,target):\n",
    "    temp_dumms_corr = pd.get_dummies(df[[col,target]]).corr()[target]\n",
    "    temp_dumms_corr = list(temp_dumms_corr[abs(temp_dumms_corr) > .15].index.drop(target))\n",
    "    return pd.get_dummies(df)[temp_dumms_corr]\n",
    "\n",
    "#### FUTURE CODE: While this works well with train data, where target is known, it doesn't work so hot\n",
    "#### with the test data. I'd have this return a list of column names in the future so it's more widely usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Neighborhoods with strong correlations to my train data\n",
    "train = pd.concat([train,find_corr_dummies(train,'Neighborhood','SalePrice')], axis=1)\n",
    "\n",
    "## Adding Neighborhoods with strong correlations to my test data\n",
    "#### As addressed above, I couldn't apply find_corr_dummies to the test data (or use its output)\n",
    "test = pd.concat([test, \n",
    "                  pd.get_dummies(test)[['Neighborhood_Edwards', 'Neighborhood_IDOTRR', 'Neighborhood_NAmes',\n",
    "        'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown',\n",
    "        'Neighborhood_Somerst', 'Neighborhood_StoneBr']]],\n",
    "                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding strong correlations for MSSubClass\n",
    "#### NOTE: I never added this to test because the correlations were insignificant\n",
    "train = pd.concat([train,find_corr_dummies(train,'MSSubClass','SalePrice')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding a variable for the mansions found in the data that are cheap for their other features\n",
    "## 2 mansions were identified that drove high MSE and lay way outside the expectations\n",
    "train['mansion'] = [1 if x > 5000 else 0 for x in train['TotalArea']]\n",
    "test['mansion'] = [1 if x > 5000 else 0 for x in test['TotalArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA Identified a skew in the target, so log is used to make target more normal\n",
    "train['SalePriceLog'] = np.log(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting data\n",
    "train.to_csv('../datasets/exports/train_clean.csv', index=False)\n",
    "test.to_csv('../datasets/exports/test_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
